{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize camera\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for default camera\n",
    "cap.set(3, 1280)  # frame width\n",
    "cap.set(4, 720)   # frame height\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera could not be opened.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()  # Read a frame\n",
    "    if not success:\n",
    "        print(\"Failed to read frame\")\n",
    "        continue\n",
    "    \n",
    "    cv2.imshow(\"Webcam Feed\", img)  # Display the frame\n",
    "    \n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_recognition imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "print(\"face_recognition imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import face_recognition\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face matched! Starting the exam...\n",
      "Starting the exam...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Absolute path to the folder where student images are stored\n",
    "STUDENT_IMAGES_FOLDER = \"Images\"  \n",
    "\n",
    "def get_student_image_from_folder(student_id):\n",
    "    \"\"\"Fetch student's image and encoding from a folder based on student ID.\"\"\"\n",
    "    image_path = os.path.join(STUDENT_IMAGES_FOLDER, f\"{student_id}.jpg\")\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            # Load the image and encode it\n",
    "            reference_image = face_recognition.load_image_file(image_path)\n",
    "            reference_encoding = face_recognition.face_encodings(reference_image)[0]\n",
    "            # Convert to BGR format for OpenCV display\n",
    "            reference_image_bgr = cv2.cvtColor(reference_image, cv2.COLOR_RGB2BGR)\n",
    "            return reference_image_bgr, reference_encoding\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or encoding image: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Image not found in the folder.\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def start_exam():\n",
    "    \"\"\"Function to simulate starting the exam.\"\"\"\n",
    "    print(\"Starting the exam...\")\n",
    "\n",
    "def webcam_verification(student_id):\n",
    "    \"\"\"Verify student's face using webcam with split-screen display.\"\"\"\n",
    "    reference_image, reference_encoding = get_student_image_from_folder(student_id)\n",
    "    if reference_encoding is None:\n",
    "        print(\"Failed to fetch reference image from the folder.\")\n",
    "        return\n",
    "\n",
    "    # Open the webcam and start capturing frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the live webcam image\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        match_found = False\n",
    "        for face_encoding in face_encodings:\n",
    "            # Compare the detected face with the reference encoding\n",
    "            matches = face_recognition.compare_faces([reference_encoding], face_encoding)\n",
    "            if True in matches:\n",
    "                match_found = True\n",
    "                break\n",
    "\n",
    "        # Prepare the split-screen image\n",
    "        split_screen = None\n",
    "        if reference_image is not None:\n",
    "            # Resize the reference image to match webcam feed dimensions\n",
    "            reference_resized = cv2.resize(reference_image, (frame.shape[1], frame.shape[0]))\n",
    "            split_screen = np.hstack((frame, reference_resized))  # Combine images side-by-side\n",
    "\n",
    "        # Display the split-screen\n",
    "        if split_screen is not None:\n",
    "            if match_found:\n",
    "                cv2.putText(split_screen, \"Face Matched! You can start the exam.\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(split_screen, \"Face Not Matched. Try Again.\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Verification\", split_screen)\n",
    "\n",
    "        # If match found, start the exam\n",
    "        if match_found:\n",
    "            print(\"Face matched! Starting the exam...\")\n",
    "            start_exam()  # Call your function to start the exam\n",
    "            break\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Tkinter GUI setup for exam verification\n",
    "root = Tk()\n",
    "root.title(\"Student Face Verification\")\n",
    "\n",
    "# Label to instruct the student\n",
    "lbl_instruction = Label(root, text=\"Please verify your face to start the exam\", font=(\"Helvetica\", 16))\n",
    "lbl_instruction.pack(pady=20)\n",
    "\n",
    "# Button to initiate webcam verification\n",
    "btn_start = Button(root, text=\"Start Verification\", font=(\"Helvetica\", 14), command=lambda: webcam_verification(student_id=\"1234\"))\n",
    "btn_start.pack(pady=20)\n",
    "\n",
    "# Run the Tkinter GUI\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam and close OpenCV windows when done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face matched! Starting the exam...\n"
     ]
    }
   ],
   "source": [
    "# Final code\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "import face_recognition\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Absolute path to the folder where student images are stored\n",
    "STUDENT_IMAGES_FOLDER = \"Images\"  \n",
    "\n",
    "def get_student_image_from_folder(student_id):\n",
    "    \"\"\"Fetch student's image and encoding from a folder based on student ID.\"\"\"\n",
    "    image_path = os.path.join(STUDENT_IMAGES_FOLDER, f\"{student_id}.jpg\")\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            # Load the image and encode it\n",
    "            reference_image = face_recognition.load_image_file(image_path)\n",
    "            reference_encoding = face_recognition.face_encodings(reference_image)[0]\n",
    "            # Convert to BGR format for OpenCV display\n",
    "            reference_image_bgr = cv2.cvtColor(reference_image, cv2.COLOR_RGB2BGR)\n",
    "            return reference_image_bgr, reference_encoding\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or encoding image: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Image not found in the folder.\")\n",
    "        return None, None\n",
    "\n",
    "# Function to start webcam verification\n",
    "def webcam_verification(student_id):\n",
    "    \"\"\"Verify student's face using webcam with split-screen display.\"\"\"\n",
    "    reference_image, reference_encoding = get_student_image_from_folder(student_id)\n",
    "    if reference_encoding is None:\n",
    "        print(\"Failed to fetch reference image from the folder.\")\n",
    "        return\n",
    "\n",
    "    start_time = time.time()  # Record the time when verification starts\n",
    "    match_found = False\n",
    "\n",
    "    # Open the webcam and start capturing frames\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the live webcam image\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for face_encoding in face_encodings:\n",
    "            # Compare the detected face with the reference encoding\n",
    "            matches = face_recognition.compare_faces([reference_encoding], face_encoding)\n",
    "            if True in matches:\n",
    "                match_found = True\n",
    "                break\n",
    "\n",
    "        # Prepare the split-screen image\n",
    "        split_screen = None\n",
    "        if reference_image is not None:\n",
    "            # Resize the reference image to match webcam feed dimensions\n",
    "            reference_resized = cv2.resize(reference_image, (frame.shape[1], frame.shape[0]))\n",
    "            split_screen = np.hstack((frame, reference_resized))  # Combine images side-by-side\n",
    "\n",
    "        # Display the split-screen\n",
    "        if split_screen is not None:\n",
    "            if match_found:\n",
    "                cv2.putText(split_screen, \"Face Matched! You can start the exam.\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(split_screen, \"Face Not Matched. Try Again.\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Verification\", split_screen)\n",
    "\n",
    "        # Stop webcam feed after 10 seconds if no match is found\n",
    "        if not match_found and time.time() - start_time > 10:\n",
    "            print(\"Face not matched within 10 seconds. Stopping webcam.\")\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        # If match found, start the exam\n",
    "        if match_found:\n",
    "            print(\"Face matched! Starting the exam...\")\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "    # Keep the split-screen display open\n",
    "    while True:\n",
    "        if split_screen is not None:\n",
    "            cv2.imshow(\"Verification\", split_screen)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('r'):  # Restart verification if 'r' is pressed\n",
    "            print(\"Restarting verification...\")\n",
    "            webcam_verification(student_id)\n",
    "            break\n",
    "        elif key == ord('q'):  # Exit if 'q' is pressed\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "# Tkinter GUI setup for exam verification\n",
    "root = Tk()\n",
    "root.title(\"Student Face Verification\")\n",
    "\n",
    "# Label to instruct the student\n",
    "lbl_instruction = Label(root, text=\"Please verify your face to start the exam\", font=(\"Helvetica\", 16))\n",
    "lbl_instruction.pack(pady=20)\n",
    "\n",
    "# Button to initiate webcam verification\n",
    "btn_start = Button(root, text=\"Start Verification\", font=(\"Helvetica\", 14), command=lambda: webcam_verification(student_id=\"1234\"))\n",
    "btn_start.pack(pady=20)\n",
    "\n",
    "# Run the Tkinter GUI\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backend \n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Folder where student images are stored\n",
    "STUDENT_IMAGES_FOLDER = r\"C:\\Users\\amren\\OneDrive\\Desktop\\student_images\"\n",
    "\n",
    "def get_student_image_from_folder(student_id):\n",
    "    \"\"\"Fetch student's image and encoding from a folder based on student ID.\"\"\"\n",
    "    image_path = os.path.join(STUDENT_IMAGES_FOLDER, f\"{student_id}.jpg\")\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            reference_image = face_recognition.load_image_file(image_path)\n",
    "            reference_encoding = face_recognition.face_encodings(reference_image)[0]\n",
    "            reference_image_bgr = cv2.cvtColor(reference_image, cv2.COLOR_RGB2BGR)\n",
    "            return reference_image_bgr, reference_encoding\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or encoding image: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Image not found in the folder.\")\n",
    "        return None, None\n",
    "\n",
    "def verify_face(student_id, timeout=10):\n",
    "    \"\"\"Verify student's face using webcam with a timeout.\"\"\"\n",
    "    reference_image, reference_encoding = get_student_image_from_folder(student_id)\n",
    "    if reference_encoding is None:\n",
    "        return {\"status\": \"failed\", \"message\": \"Student image not found or invalid.\"}\n",
    "\n",
    "    start_time = time.time()\n",
    "    match_found = False\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces([reference_encoding], face_encoding)\n",
    "            if True in matches:\n",
    "                match_found = True\n",
    "                break\n",
    "\n",
    "        if time.time() - start_time > timeout:\n",
    "            cap.release()\n",
    "            return {\"status\": \"failed\", \"message\": \"Face not matched within timeout.\"}\n",
    "\n",
    "        if match_found:\n",
    "            cap.release()\n",
    "            return {\"status\": \"success\", \"message\": \"Face matched. You can start the exam.\"}\n",
    "\n",
    "    cap.release()\n",
    "    return {\"status\": \"failed\", \"message\": \"Verification aborted.\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Django\n",
    "from django.http import JsonResponse\n",
    "from django.views.decorators.csrf import csrf_exempt\n",
    "from .face_verification import verify_face\n",
    "import json\n",
    "\n",
    "@csrf_exempt\n",
    "def verify_face_view(request):\n",
    "    if request.method == 'POST':\n",
    "        data = json.loads(request.body)\n",
    "        student_id = data.get(\"student_id\")\n",
    "\n",
    "        if not student_id:\n",
    "            return JsonResponse({\"status\": \"failed\", \"message\": \"Student ID is required.\"})\n",
    "\n",
    "        result = verify_face(student_id)\n",
    "        return JsonResponse(result)\n",
    "\n",
    "    return JsonResponse({\"status\": \"failed\", \"message\": \"Invalid request method.\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
